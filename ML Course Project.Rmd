---
title: "ML Course Project"
author: "Asoskov Dmitrii"
date: "2024-02-05"
output: html_document
---

## Some neccesary things before modeling

Firstly, I need to download the training and testing datasets and provide a short explaratory analysis.

```{r, echo = TRUE}
train <- read.csv("C:/Users/dmitr/Downloads/pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("C:/Users/dmitr/Downloads/pml-testing.csv", na.strings=c("NA","#DIV/0!",""))

str(train)
```


```{r, echo = FALSE}
library(ggplot2)
library(caret)
library(RColorBrewer)
library(randomForest)
library(gbm3)
library(rattle)
library(rpart)
```

As I understood from the structure of the data first seven variables are not predictors so I need to drop them out too.

```{r, echo = TRUE}
train <- train[,colSums(is.na(train)) == 0]
test <- test[,colSums(is.na(test)) == 0]
train <- train[,-c(1:7)]
test <- test[,-c(1:7)]
```

Next step is to split train dataset in order to comply with cross-validation requirement.

```{r, echo = TRUE}
set.seed(1)
trIndex = createDataPartition(train$classe, p = 0.7, list=FALSE)
train_cv = train[trIndex,]
test_cv = train[-trIndex,] 
names(test_cv)
```

Now I want to analize the outcome variable.

```{r, echo = TRUE}
summary(train$classe)
table(train$classe)

ggplot(data = train_cv, aes(x = classe)) +
  geom_bar(color = "blue", fill = "blue") + 
  labs(title = "Histogram of classe", x = "classe", y = "frequency")
```


## Modeling

# First model: Classification Tree

```{r, echo=TRUE}
model_tree <- rpart(classe ~ ., data = train_cv, method = "class")
fancyRpartPlot(model_tree)
```
Predictions of 1 model:

```{r, echo = TRUE}
predictions_tree <- predict(model_tree, test_cv, type = "class")
table(predictions_tree)
table(test_cv$classe)

predictions_tree <- factor(predictions_tree)
test_cv$classe <- factor(test_cv$classe)
confusionMatrix(predictions_tree, test_cv$classe)
```
# Second model: Random Forest

```{r, echo = TRUE}
train_cv$classe <- factor(train_cv$classe)
model_rf <- randomForest(classe ~ ., data = train_cv)
predictions_rf <- predict(model_rf, test_cv)
confusionMatrix(predictions_rf, test_cv$classe)
head(varImp(model_rf))
```
So, accuracy is higher for Random Forest, and I'm going to make predictions on real test set using rf model.

```{r, echo = TRUE}
pred <- predict(model_rf, test)
pred
```